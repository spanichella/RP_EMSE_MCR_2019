Time stamp,2018/07/04 7:06:23 PM OEZ,2018/07/04 9:54:46 PM OEZ,2018/07/05 8:43:53 AM OEZ,2018/07/06 12:04:40 AM OEZ,2018/07/06 10:11:24 AM OEZ,2018/07/10 10:33:54 AM OEZ,2018/07/10 11:37:26 AM OEZ,2018/07/15 8:58:20 AM OEZ,2018/07/17 11:25:02 AM OEZ,2018/07/17 12:00:00 PM OEZ,2018/07/17 12:23:01 PM OEZ,2018/07/17 1:24:19 PM OEZ,2018/07/17 2:11:16 PM OEZ,2018/07/17 5:16:27 PM OEZ,2018/07/17 11:47:56 PM OEZ,2018/07/18 9:15:17 AM OEZ,2018/07/18 1:29:14 PM OEZ,2018/07/19 7:36:04 PM OEZ,2018/07/19 10:19:01 PM OEZ,2018/07/20 5:39:36 PM OEZ,2018/07/24 9:28:35 AM OEZ,2018/07/24 12:54:35 PM OEZ,2018/07/25 8:30:20 AM OEZ,2018/07/25 4:04:11 PM OEZ,2018/07/26 10:45:22 AM OEZ,2018/07/26 10:51:16 AM OEZ,2018/07/26 12:17:18 PM OEZ,2018/07/27 8:52:33 AM OEZ,2018/07/27 10:25:06 AM OEZ,2018/07/27 6:36:57 PM OEZ,2018/07/28 2:15:11 AM OEZ,2018/07/28 5:26:47 AM OEZ,2018/07/30 5:33:39 AM OEZ,2018/07/30 5:54:57 AM OEZ,2018/07/30 6:04:04 AM OEZ,2018/07/30 6:16:20 AM OEZ,2018/07/30 6:28:27 AM OEZ,2018/07/30 6:37:52 AM OEZ,2018/07/30 6:45:15 AM OEZ,2018/07/30 6:53:25 AM OEZ,2018/07/30 10:46:44 AM OEZ,2018/08/01 11:13:21 AM OEZ,2018/08/02 9:55:26 PM OEZ,2018/08/05 9:03:08 AM OEZ,2018/08/07 9:38:34 AM OEZ,2018/08/08 10:07:08 AM OEZ,2018/08/09 9:15:57 AM OEZ,2018/08/13 8:08:58 PM OEZ,2018/08/13 8:46:16 PM OEZ,2018/08/13 8:51:59 PM OEZ,2018/08/13 8:55:31 PM OEZ,2018/08/13 9:00:45 PM OEZ
Participant ID,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52
What is your current job?,Industrial Developer,Other Occupation,Industrial Developer,Other Occupation,Senior Researcher,CS Student,CS Student,Open Source Developer,Senior Researcher,Senior Researcher,Industrial Developer,Industrial Developer,Other Occupation,Senior Researcher,Industrial Developer,CS Student,CS Student,Senior Researcher,Other Occupation,Industrial Developer,Industrial Developer,Senior Researcher,Senior Researcher,Industrial Developer,Senior Researcher,Senior Researcher,Open Source Developer,Industrial Developer,Senior Researcher,Open Source Developer,Industrial Developer,Other Occupation,Industrial Developer,Industrial Developer,Industrial Developer,Industrial Developer,Industrial Developer,Industrial Developer,Industrial Developer,Industrial Developer,Industrial Developer,Industrial Developer,Industrial Developer,Industrial Developer,Open Source Developer,CS Student,Open Source Developer,Industrial Developer,Industrial Developer,Industrial Developer,Open Source Developer,Industrial Developer
"Approximatively, what is the size (in terms of lines of code) of the system you are contributing in most?",50000,"no idea, we never counted",10000,0,2000,"20,000",8000,20000,500000,100K in average considering the various projects.,20000,"150,000",30000,I don't really contribute to a software system when perfirming research,3000,4000,At Uni (1000+). At Work (10'000+),300K LoC,16000,10K of Scala,around 670KLOC...,15000,16000,25,50K,12000,1600KLOC I think (Working ina collaborative and OSS environment).,"1,200,000 - 1,500,000 LOC",50000,150k lines,5000,"100,000+",25000,"45,000","100,000","30,000","55,000","250,000 - 350,000","200,000","800,000 - 1000,000",26000,8,550000,21,276000,15000,130000,10,45000,1400000,14,800000
What is the approximate size of the development team of the system you are contributing to most?,6,6,4,20,3,1,1,4,15,8,2,7,10,"again, I have a research team, not a development team ;(",5000,4,At Uni (1-3 People). At Work (10-20 People).,4,3,5,120,6,1,400KLOC in average per project,5,1,"Not sure, I think > 120 developers ",75,4,20 developers,3,1,8,12,45,14,22,60,Oct-15,80,10,26KLOC,25,410000,30,4,12,300000,5,60,175000,70
How many years of programming experience do you have?,> 8,< 2,> 8,> 8,> 8,Between 5 and 8,Between 2 and 5,Between 2 and 5,> 8,> 8,> 8,> 8,Between 2 and 5,> 8,> 8,Between 5 and 8,Between 2 and 5,> 8,Between 5 and 8,Between 5 and 8,> 8,Between 5 and 8,Between 5 and 8,> 8,> 8,Between 5 and 8,> 8,> 8,Between 5 and 8,> 8,Between 2 and 5,> 8,> 8,> 8,> 8,Between 5 and 8,> 8,> 8,> 8,> 8,Between 5 and 8,> 8,> 8,> 8,> 8,Between 2 and 5,> 8,> 8,> 8,> 8,> 8,> 8
How do you rate your programming experience?,5,1,4,3,4,4,3,3,3,4,4,4,3,5,4,3,3,5,4,5,5,3,4,5,5,5,5,5,4,4,3,5,4,5,5,4,5,4,5,5,4,5,5,5,5,3,4,4,5,5,5,5
What is code review?,"A peer review process to ensure newly committed or changed code:
- does meet the team's definition of done (completeness)
- does meet the standards defined by the team for the project (quality)
- is easily understandable and not overly clever (principle of least surprise)
- is adequate to solve the problem at hand","An opportunity to catch issues, share knowledge and expertise, improve code quality, ensure code conventions for comprehensibility and maintainability (can be automated), catch lacking test automation coverage, catch duplication, etc.","A step in the software development process, where the code is checked by a second developer in order to spot any issues before acceptance tests.",Reviewing the code for the standards and logic,An inspection process for checking that the new code meets the standards of the codebase.,The process of reading code written by others in order to improve it's quality and fix potential errors.,"Checking new code for correctness, adequacy and quality (e.g. lenght, programming patterns)",Intensive code inspection of change of another person --> Quality assurance and opinion exchange,"the systematic process of investigating code to establish its quality, its quantities, as well as classifying its problems","Manual inspection of code written by other people, this to improve the overall quality of the production/test code and related artifacts (e.g., the documentation)",Peer review of the source code.,The process of checking code for quality properties by one or more people who did not write the code being checked.,Systematic examination of source code belonging to a change,It is the practice of reviewing code to avoid bugs and inconsistencies with the software project,process of code analyse and change suggestion based on requirements and metrics.,"inspection of source code through at least one other developer (i.e., non-author)",Reviewing the code written by other developers in order to improve the quality and decrease the number of defects. ,"That's a complex question. :) Technically, a code review is two (or more) people going over a set of changes (""reviewer(s)"" and ""implementer"") to decide whether these changes can be merged back into the main development line. The reason why code reviews are conducted strongly depends on the project and is typically much more complex than just checking the correctness of the code.",Code Review is a common Software Engineering practice involving external people inspecting software developed by other in order to find defects or improve the quality of the code itself,"Code review is the process of getting approvals from one's peers on one's code. This process involves questions, suggestions, and modifications on the new code to be integrated in the project.","A development practice in which developers focus on discovering bugs, defects and other mistakes in the code written by other developers. This can be done in person or via online meeting, or some automated tool support (e.g., Gerrit).",a development practices where developers inspect code to improve its quality,"I have no idea, I have never done a code review and never had my code reviewed (the downside of research prototype developments)",Manual inspection of code written by other developers. The inspection is usually made by more developers to let less experienced one improve their code quality.,"Code review is systematic examination (sometimes referred to as peer review) of computer source code. It is intended to find mistakes overlooked in software development, improving the overall quality of software. Reviews are done in various forms such as pair programming, informal walkthroughs, and formal inspections.",A process of inspecting source code.,A semi automated process performed to detect defects or imperfections in the code. I mainly use Gerrit for it in my main projects.,"A software development practice aimed at improving the code of other developers, especially the one of junior developers. Code Review is also not the place to ask for implementing new features.",A systematic examination of code before being merged in a project. ,"An tech-assisted means of verifying that new code has correct design and functions correctly.  It involves both automated testing, and manual review by other developers.",To validate the approach taken by a fellow developer to provide feedback with the goal of ensuring consistency and cohesion amongst a team of developers,"Secondary set of eyes looking at code or find issues: coding, security,and Corp standards",code inspection to find imperfections in the code,importance dev practise to  get feedback on our code from more experienced developers...,important practise to improve quality of our software and sharing knowledge.,we do it to improve technical and social skills in the team.,"formal or semiformal way to sharing experience on how to write better test, production code, documentation and othe rartifacts","we do it for teach newcomers programming practices, sharing knowledge and improve the software product.",review of code written by colleagues.,a way to share information between developers' teams distributed in different geographic regions and for improving their code.,"reading over the code of another developer, looking for mistakes, checking correct house-styles and testing the functionality.",a practice to help developers improve their code.,important activity to improve the code.,practice useful to help improve code of collegues or junior developers,very useful practise to improve the code or product of our ongoing projects...,a systematic inspection of code written by other developers aimed at improving the software quality,important task for sharing knowledge between developers and improve the test and production code.,activity aimed at support team collaborations and quality of software products,inspection of code,reviewing code/patches of others,consists in reviewing the code of collegues,systemating reviewing activities on code written by others
Do you think the taxonomy covers all changes that occur in code review?,No,No,No,No,Yes,Yes,No,Yes,Yes,Yes,Yes,No,Yes,No,No,Yes,Yes,No,Yes,No,Yes,Yes,Yes,Yes,Yes,Yes,No,Yes,Yes,No,Yes,No,Yes,No,Yes,Yes,No,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Yes
"If your previous answer was ""No"", please explain why you think the taxonomy is not exhaustive? Otherwise, you can also send us a modified version of the taxonomy per e-mail to","- One thing I miss is cleanup/refactoring of the actual git commit graph, e.g. interactive rebase, squashing etc. (depending on team conventions)
- even though this is covered by ""non-source files"" -> ""config files"" -> ""others"" I would consider adding runtime configuration (docker configs, ansible playbooks, deployment configs) as a separate item in config section","It's quite comprehensive, but I don't think it can or even should be exhaustive. Also, I don't agree with some terminology used; like what is source code and what is ""outside"". In my opinion a lot more files belong to the application's source. Example: config files or library versions to build the application.",typos,Style and logic,,,Perhaps it's included in Larger Defects: Completeness but I think that many good code reviews are covering edge cases and that the solution is covering the whole problem. --> Maybe that part could be expanded.,,,,,"How would you categorize a review comment like 'This function needs log messages'? Maybe that's 'New Functionality' (if there aren't logging statements already), maybe it's 'Standard Coding Conventions' (if there's a logging standard for the project), maybe there should also be a 'Logging' category as there is for Testing.",,"I think the taxonomy covers a good part of the code reviewing process, but you could add something about ""versioning"".  I remember when I worked as a software developer, the header of the Java classes should contain the most recent SVN version that they were modified. I know this information could probably be fetched from the SVN itself, but maybe the company wants to quickly identify the latest revision of the file.",One of big types of code change come from side effect of another code change. domino effect has occur (most time in long period of time). ,IMHO: GUI defects are not necessarily large defects,,"The changes seem to be oriented on what you would get from a ""diff viewer"", I think you are missing more semantic changes. In my experience, code reviews often result in a change to the system architecture, like splitting an interface into two distinct interfaces, introducing abstractions, or the inclusion of design patterns. These more ""object-oriented"" changes are missing right now in the taxonomy.",,,"I have to say that the completeness of the taxonomy depends some time on the specific software organization: in general most software software look at the above aspects during code review, however, specific companies could have more specific requirements. Let's for example consider a company working on self-driving cars, in that case code review will require also to observe potential security and or testing issues, an aspect not considered massively in this taxonomy. I would consider to add also changes in the taxonomy that could be relevant also for less general software companies.",,,,,/,"Partially... we mainly care, with the same importance, to
-Documentation and coding style. 
-Architecture patterns.
-Error handling.
-Test coverage. 
-Performance monitoring.
-Security. ",,,"Should mention functional or integration testing, where software is integrated as it would be in production, and run against a battery of automated tests.",,Security is a major aspect,,maybe security is something we care also..,,,"performance and security are missing i think, Is ASATs static analysis? In some cases the acronyms do not help understanding what actually there is in the taxonomy.",,,,,,,,,,,,,,,
"In your opinion, issues regarding which Categories/Topics (above taxonomy) occur the most inside code review? Please create a ranking listing the 5 most frequent ones.","Testing, Refactorings, Best practice, Bug-Fix, Config files/Language specific","Best practice, refactoring, bug fix, testing, code documentation","Best Practice 5
Testing 3
Refactoring 2",Logic,"style, complex code, consistency, new functionality, completeness",Style / Solution Approach / Check / Organization / Documentation,"Styling issues; 
Organization: Complex Code;
Textual Documentation: Comments;
Larger Defects: Completeness
Solution Approach: Semantic Duplication; 
","1. Solution approach, 2. Organization, 3. Check, 4. Interface, 5. Logic",I did not understand this question,"Style (all of them), documentation-testual documentation, structure (semantic-dead code, testing, coding conventions and all topics in organization), runtime configurations,  some time, data & resource manipulation","Data & Resouce Manipulation, Algorithmic Performance, New Functionality, Consistency, Move Functionality","Standard Coding Conventions, Refactoring (expressed in taxonomy by Semantic Duplication, Semantic Dead Code), Complex Code/Simplification",Style; Textual Documentation; Solution Approach; Larger Defects; Interface,"1 - Solution approach
2 - Organization
3 - Resource
4 - Interface
5 - Style
6 - Documentation",Refactor; Dead code; Duplicates; all part of Logic; new functionally (if you do not means classification functional/non-factional requirements),1) Style 2) Structure 3) Documentation 4) Resource 5) Check,Style > Structure > Resource > Logic > Documentation,"Testing (most frequent), design (not covered), solution approach, Naming, style","Complex code/simplification, algorithm/performance, standard coding conventions, move functionality, consistency","Standard Coding Convention
Naming
Move Functionality
Completeness
Consistency","style, documentation and structure are the most recurrent with focus on testing and quality of code :) Other changes should be more elaborate, with more appropriate descriptions, ad in the other parts of the taxonomy. I also thing that in some cases, ""interface, logic and resource are also important aspect""..","docum, style, structure, logic, check (and also configuration aspectes related to the CR itself, e.g., the configuration of ASATs)",N.A,"Documentation, style, structure, resources, logic (I would put here at the same level of logic also tools and runtime configurations)","Algorithm and Performance, comments, semantic duplication, consistency, , semantic dead code","style, structure, logic","we mainly care, with the same importance, to 
-Documentation and coding style.
-Architecture patterns. - structure
-Error handling. - defect
-Test coverage. 
-Performance monitoring.
-Security. ","Best practices and design pattern usage - structure
Performance
Correctness in unanticipated cases - defects
Documentation & coding style
Maybe also Security issues (I do not see it here in the taxonomy..)","Logic, Interface, maintainability, style, structure,  ","From an automated tools: Code coverage, and ""lint"" (style and structure) tests that can be generated by automated 

From humans: documentation and design/organization issues","Logic, Organization, Solution Approach, Textual Documentation, Style",Security,"structure, style/documentation, interface, logic, resources","In order: doc/style/structure, interface, logic, resource, security, check large defect, configuration ASATs and CD/CI scripts","style, documentation, logic, structure, and performance","style, structure, logic, resource, check","performance, security, style, documentation, logic","doc, style structure, resource, large defects.","doc, styl, structure, interface, logic BUT also resources and large defects","resources, logic, structure, check, style","Style, Solution approach, Logic, Check and Larger Defects","documentation, structure, resources, check, defects","performance, gui, logic, style, configuration","doc, structure, resource, other changes, resources","style, structure, logic, other changes ","other (configuration cd/ci and asat configuration), doc, structure, resources, logic","other changes (cd/ci configurations, runtime, static analysis configurations )
structure (test and production code)
documentation
logic
resources

Code review is less about defects I think.","CD/CI configurations, documentation, structure, resource, interface","logic, resource, other configuration, structure","resource, configuration, structure, documentation and logic","structure, documentation, logic, interface, resources","other changes (configuration cd/ci and static analysis tools), resources, logic, check, structure"
What kind of feedback do you expect from other developers during code review?,"High-Level feedback about structure, completeness, clean code aspects",Anything that they see could be improved; provided in a constructive way,"Missed of possible business cases
Not enough code coverage
Existing / Simpler solutions",Review comments ,The main one is to check consistency of my code with the codebase.,Error corrections and input for better/different coding approaches,"Feedback on how to improve efficiency (shorten code);
What edge cases they thought about;
Useful programming patterns / ideas for other problems (it's already ""too late"" for this one)","- Clean Code Feedback
- Logic testing --> Does it make sense?
- Suggestion to rewrite it in a cleaner way
- Styling feedback",whether my classifications and understanding is correct,"On the style, documentation, structure (duplicated-dead code, testing, coding conventions and all topics in organization), test/code quality in general, recommendation about runtime configurations, data & resource utilisation, ASAT configuration.",Brief and constructive. I need to know the exact reasoning behind the requested change.,"Specifics about changes needed in the code, general comments about opportunities to improve my coding.",Solution-based feedback ,I expect a clear feedback on how to improve my current solution,just report of changes,"Suggestions to improve the readability (and thus maintainability) of code, raising quality concerns","Do you understand what I have done? (documentation, structure and logic wise => also for maintaining it in the future)
Does my work make sense i.e. is it efficient for the task? (rating resource management, unnecessary looping, etc.)
Possible ways to improve the solution/fix/commit...","I strongly prefer face-to-face code reviews rather than tool supported code reviews. CR is a very communicative process, in which the implementer presents his work, the reviewer questions design decisions and based on the answers one or the other is convinced that the current version is fine or should be further improved.","Feedback about improving design of a solution (in the sense of interface usage for instance, or some design pattern application); improving a given implementation with less space and time complexity",I like to get feedback on whether my code can be written in a better way such that it runs faster or it reads better.,"Any feedback on my coding style, the accuracy comprehensibility of the documentation, my code structure, the quality of my test and production code with some check on the logic and resource consumption of the proposed solution/patch.","while I usually receive feedback on docum, style, structure, would be useful to have in general more feedback on logic, check, testing and production code quality.",N.A,"Anything to improve my code style and quality, in general recommendation on how to write better code and if possible,  (and even partial) alternative solutions to the problem addressed in the patch.",potential (performance) bug and design problem,Mostly regarding comprehensibility issues,"I would like to share our experience a little bit. We are doing code review for a few years now we have the following goals in this process:

1)To predict unexpected app behavior, 2)To avoid annoticed critical bugs 3)To avoid app crash in final production. 4)Easy adding of the new functionality.

 Our code review process involves line-by-line code analysis, a source code review checklist, and documentation for suggesting improvements. Thus, what we expect from other developers recommendation on:
-Documentation and coding style.
-Architecture patterns. - structure
-Error handling. - defect
-Test coverage. 
-Performance monitoring.
-Security.
","This is our process description and expectations in CodRewiews:

Developers code features separate from the validated-code

When developer is ready, he/she marks feature as complete in our issue-tracker

Developer checks-in the code (production and test code for quality issues, e.g., 
structure, coverage, etc.)

""An automated build is triggered to run our unit-tests, and runs some automated quality-checks. When this fails the developer is notified, and requested to fix issues. Ideal shoul would happen in isolation. So if one developer breaks the build, this should not affect the other developers working on the same project.""
I think some sort of automation should be provided before this process to the developers in my opinion.

When the build is ok, a ""manager"" is informed that there is a new feature ready. He checks the quality of the code, and checks if the feature is working as expected. If there are issues, these are send to the developer to correct them. If everything is ok, the manager commits the new feature to the ""main""-branch.
",If there are problems with the code,"Validation that the design approach taken is the correct one, and bringing up issues or cases that hadn't been considered in the design.  Fixes to documentation.",It depends on my skill level in the particular language and framework. When I'm less experienced Style and Textual Documentation. When I'm more experienced Organization and Solution Approach.,Better ways to do things ,"structure, style/documentation, interface, logic, resources, security aspect, feedback on how to improve performance of my code (if possible), quality of test and production code...","feedback on doc/style/structure, interface, logic, resource, security, check large defect, configuration ASATs and CD/CI scripts","at least feedback on style, documentation, logic but in some case would be nice on performance and quality of test and production code","on any of the topics in the taxonomy possible, but usually I receive feedback on style, structure, logic, check","clearly, feedback on performance, security, style, documentation, logic
","on all : doc, style structure, resource, large defects.","mainly doc, styl, structure, interface, logic BUT also resources and large defects","resources, logic, structure, check, style and quality of test code.",Comments on each error made in the code and comments if something can be improved.,feedback on all aspect of the taxonomy..,"usually i receive them on ""logic, style, configuration""","feedback on all elements of the taxonomy possibly, but at least on ""doc, structure, resource, other changes, resources""","look at my code, see what to improve, for example suggesting refactoring, something not really working in the logic of my code (especially in potentially cloned code), detect redundant/cloned/useless code (to simplify it).",to improve my code,"feedback on:

other changes (cd/ci configurations, runtime, static analysis configurations )
structure (test and production code)
documentation
logic
resources",any feedback on the taxonomy,all elements of the taoxnomy,whole elements of the taxonomy.,do not know/do not want to say,feedback in all elements of the taxonomy
What kind of feedback do you usually receive from other developers during code review?,"Questions about how/why something works (hinting to code readability issues), naming suggestions, hints about missing tests or possible bugs",None as I rarely am on the receiver side,"Typos, Missing Tests",Review comments ,Feedback regarding style or completeness.,Error corrections and input for better/different coding approaches,short statements if it suffices in terms of quality and completeness.,"- Clean Code Feedback
- Logic testing --> Does it make sense?
- Suggestion to rewrite it in a cleaner way
- Styling feedback

I guess the same as I expect=)",confirmation and examples,"style, test/code quality in general...","Mostly constructive, sometimes blunt. But that is alright, as long as the code base gets better.","Specifics about changes needed in the code, general comments about opportunities to improve my coding.",Point out problems with the code without suggestions related to how to fix the problems,whether my current solution is good and how can I improve it to make it even better,,,If they are ok with the changes. If the amount of documentation is sufficient and precise enough. If they agree with the approach of the solution to fix the problem. Tips and improvements...,See last answer.,"Feedback about design of a solution (usage of delegation, composition and abstraction in general)","Mostly I receive questions on why certain things are done the way they are. In other words, my peers require clarifications on the design decisions that I made. Another type of feedback is regarding the coding style and where functionalities should be placed","Usually on my coding style, the accuracy comprehensibility of the produced/updated documentation, my code structure, the quality of my test and production code"," I usually receive feedback on docum, style, structure",,"Usually, it depends from the developers experience, but in most cases comments are related to code style, documentation and logic of the code.",no much,/,"mainly recommendation on:
-Documentation and coding style.
-Error handling. - defect
-Test coverage. 
- some time on Security aspects
","Developer checks-in the code (production and test code for quality issues, e.g., 
structure, coverage, etc.), Documentation & coding style

In some rare cases feedback also on:

Performance
Correctness in unanticipated cases - defects
Security issues
",Feedback about potential problems or suggestions for improvement ,Usually the kinds mentioned above.,"Sometimes it can be very opinionated towards specific user styles, which are never quite the same across the whole team or department.
Often though it is about understanding my approach rather than requesting changes.",Not much,"structure, style/documentation, logic,  some time on the quality of test and production code...","doc/style/structure, logic and in some cases resource and security","style, documentation, logic","on style, structure, logic, check","style, documentation, logic","doc, style structure, simple defects","mainly doc, styl, structure, interface, logic RARELY on resources and large defects"," logic, structure,  style, and check in some situations",Only if an error was made.,"usually on documentation, structure would be nice to have them also on most of the categories in the taxonomy","on all performance, gui, logic, style, configuration aspects","doc, structure - for the other elements I rarely get feedback, which is pretty frustrating sometime.","it depends from the experience of reviewers, but usually I ask them to look at my code, see what to improve, for example suggesting refactoring, something not really working in the logic of my code (especially in potentially cloned code), detect redundant/cloned/useless code (to simplify it).

However, the quality of reviews vary and depend also from the deadlines of other coworkers.",to improve my code,"usually I receive them on

structure (test and production code)
documentation

but ofter the feedback arrive very late from reviewers, this is especially true in open source community.
",usually on ,usually documentation and structure of code.,"on structure, documentation and some times logic",do not know/do not want to say,usually on structure and documentation
What kind of feedback would you expect from recommender-tools during code review?,"style issues (linting), structural issues (code quality/metrics), architectural violations, clean code principle violations","""Recommender-tools""? You mean tools that provide recommendation in an automated way? If that's the case, then logic errors, lacking test coverage, unused imports, typos (assuming code style is already automatically checked by another tool)","Unnecessary / unused variables/methods
Used of deprecated code",Style,"style, complex code, consistency",Error corrections and input for better/different coding approaches,"ideas for programming patterns;
showing where similar code was used / where the same thing is happening;","
- clean code suggestion
- unused code snippet
",where to jump to,"Of two type, first i would like to know which changes are/will be required for the code review session. This would be useful to estimate the work required 
 to perform the required changes.","I would like some ranking of the severity of the issue, which could be set at the beginning of the project. Like that, I could prioritise on the issues.",Specifics about changes needed in the code.,Suggestions related to possible code changes aimed to fix the problem,"maybe some clear suggestions of what am I missing in my proposed solution, such as how can I optimize the memory usage or if I am following the code style that should be adopted",refactoring,"Change suggestions for simple automatable fixes (e.g., alike a pull request)","Static analysis suggestions but additionally check comments and documentation is available, function calls and nesting, check complexity.. Give concrete suggestions what should be changed...","I do not understand the question. I think what I get right now is the result of the build, i.e., how is the test coverage, are there style warnings, does the code compile, etc. This is all I need.","I would expect simpler checks, like the ones about style especially, or coding conventions, that could be embedded in a recommender and be project dependent","To be honest, I don't see how an automatic recommender tool can help me since I see the code review process as a communication platform between teammates. The human element is essential. However, it would be cool to get recommendations regarding the coding standards that are adopted by the team.","This is not a simple question, I think that, beside tools suggesting how to improve structure/style/documentation it would be great to have tools, anticipating the process of change. Very often during after submitting a patch, I have to wait some ""unproductive"" time before getting a feedback on my code. it would be in general useful to have tool that instantaneously provide me high- and low-level feedback on my code.",I think automation in code review is also difficult to imagine to me. Maybe because I mainly to face to face code review and my team is non so large. Probably in more industrial context tools for collaborative code review and for automating some of its activity is an important requirement.,N.A,"Manual code reviews will still be done. But tool for Code Review are not  thorough enough to catch all the common problems a senior developer detect during a manual review. But from tools, I would expect in the same way feedback encapsulating aspects related to coding or documentation styles, recommendations regarding configuration of tools, and possible, reference to alternative solution to a given problem (e.g., from StackOverflow or other sources).",code duplication problem,"Dead code analysis, duplication","recommendation on:
-Documentation and coding style for sure
-Architecture patterns. - structure would be great,
-Error handling and defects - but I think this is difficult
-Test coverage and test quality perhaps..
-Performance monitoring (did I have added a performance bug in my change?)
-Security  (did I have added a security issue in my change?)","Feedback on production and test code for quality issues (e.g., 
structure, coverage, suggestions on how to refactoring production and test code, etc.), documentation & coding style and possibly performance issues.",Is the code ready to be merged. ,"Style, coverage, lint, and automated test suite output.","Like linters do, comments of style and static analysis feedback like dead/duplicate code.",None," interface, logic, resources, security aspect, feedback on how to improve performance of my code (if possible), quality of test and production code...

usually structure, style/documentation are easier to detect and developers are more prone to give feedback on this.","possibly feedback on all issues related to doc/style/structure, interface, logic, resource, security, check large defect, configuration ASATs and CD/CI scripts","I think tools should be able to recognize, from the last change what shoul be the focus of the review: if I change somethig, he tools should give me feedback on what I have to change, add and or improve/delete.","would be could on the structure and quality of my code first, then on the performance of it, the less critical stuff, like doc/style/structure.","again , feedback on performance, security, style, documentation, logic","for sure on doc, style structure, resource, large defects.","anything could be automated, without waiting feedback of other developers: doc, styl, structure, interface,  resources. I guess logic  and large defects are difficult to automate.","would be nice feedback on how to improve my style, structure, and quality of tests",Comments on certain lines of code were improvement is possible.,"possibly feedback on the required changes, especially on the one that i usually do not receive feedback..","performance, logic, style, and configuration aspects","feedback on the quality of my test and production code, as quell as in doc, structure, resource, other changes, resources :)","I would aspect tools recommending what to improve in my code, for example suggesting refactoring operations to simplify my code, too complex and too difficult pat of my code (the logic is too difficult too get), detect redundant/cloned/useless code (to simplify it).",to improve my code,"tool for automatically help developers configuring cd/c, runtime, static analysis tools & detect issues on

structure (test and production code)
documentation
logic
resources
","documentation, structure and logic",all elements of the taoxnomy,"feedback on all elements of the taxonomy, but usually we receive them just on structure, documentation and some times logic",do not know/do not want to say,"on other changes (configuration cd/ci and static analysis tools), resources, logic, check, structure, as developers usually provide feedback on structure and documentation. "
"What kind of automation do you envision for automating code review practices? Please while answering, keep in mind that the envisioned automated tools should be related to the automation of detection/fixing the aforementioned code review issues.",Machine-Learning code-review bot that is trained by the manual code review process and can later on (with enough training data) be used to pre-screen changesets - possibly identifying a lot of possible issues before any human reviews the code.,"I really do not understand the question; what do you mean by ""what kind of automation""? Sorry that I cannot be of any help here","Remove unused code
Replace deprecated code when possible, otherwise fail the build",Style should be corrected and logic highlighted,"Checking, for example, if I am using the same name conventions of the codebase","Static code analysis (checking for dead code, correct function calls, ...)",Styling issue detection; duplicate code detection; semantical duplicate detection;  case analysis; performance analysis,"- Similar Code --> Refactoring suggestion
- Pattern recognition and also some suggestion for setup the correct pattern
- automated Documentation generation would be really cool=)",defect prediction and property level estimation for blocks of code,"On the style: would be interesting to have a tool for evaluating my style consistency with respect to the whole project (the style applied in the organization). 

documentation: documentation is usually not update and often incomplete. it would be great to have some automation to highlight the most relevant change that are needed to make it more complete and/or less inconsistent with the test/production code.

structure: it would be also interesting to get feedback 
- on the introduced  duplicated-dead code, 
- test/code smells (bad design choices) added and/or overal test/code quality and readability in general. 
etc.

Possibly recommendation on 
- runtime configurations,
 - data & resource utilisation.",Something very similar to static analysis tools (e.g. clang-tidy for C++).,"I'd hope for a tool that would compare variables, statements and function calls not only against syntax definitions but against similar variables, statements and function calls from the codebase being changed, enabling a developer to adapt to local naming customs, and to see (and match) existing examples of the code being reviewed. ",Something integrated with the development environment that is able to recognize the problems during the insertion and not later on,I expect the automation of the style and (to some extent) documentation issues. it would also be nice to automate the organization of the proposed solution. I am not sure if it is possible to automate the solution itself.,strong naming suggestion. I think we can have word-net for naming or something like it.,Fix linter style warnings,automatically fix basic and common issue (e.g. style and documenation) or give suggestions.,"I do not think that the process of code review is automatable. The easy things like test coverage or style breaks can already be checked easily with state-of-the-art tools like Maven, the rest does not follow easy to formulate rules and depends a lot on experience.",I'd like an automation pointing out to developers whether and where they have written highly inefficient code (like implementation with high space or time complexity),"I think a tool that can automatically recognize team ""culture"" and detect deviation from it, would be helpful in the reviewing process. By team culture I mean how team members name variables, where they put functionalities, how they document their code, and so on. ","I would like to have a summary of all required changes in my patch. Usually, depending on the reviewers experience and skills you get different types of feedback. It would be great to have a comprehensive tool that provide all these feedback in one shot, maybe prioritized or ranked according to the priorities/policies of the organization."," I would try to understand which problems are recurrent in code reviews, e.g.,  defining patterns and anti-patterns characterizing the ""code review process and collaborations"".  The I would automatically leverage tools for detecting such anti-patterns to highlight potential problems. Many of problems we face during code review are related to the miss match between expectations and outcomes of a code review. Reviewer provide feedback that are not exhaustive or timely reported. This makes often code reviews unproductive. A simple automation toward this direction could be predicting the required code review changes.",N.A," I would expect  static tools profiling my changes and providing me feedback encapsulating aspects related to coding or documentation styles, recommendations regarding configuration of tools, and possible, reference to alternative solution to a given problem (e.g., from StackOverflow or other sources). Clearly, even recommendation on the general required changes on a submitted patch would be really useful in my opinion.",change explanation,"Mostly regarding style, interface, organization","It would be great to have automation that not only provide information on the performed change, but actually predict issues and/or is able to answer the following questions automatically:

- did I have introduced imperfections at the level of documentation and coding style..?
- did I have introduced imperfections at the level of Architecture patterns. ?
- did I have introduced imperfections at the level of Error handling and defects?
- did I have introduced imperfections at the level of Test coverage and test quality?
- did I have added a performance bug in my change?
- did I have added a security bug in my change?

Clearly having the location (e.g., the set of files) where the problem was introduced would be relevant too..
","Let me say that I would like automated feedback on production and test code for quality issues (e.g.,  structure, coverage, suggestions on how to refactoring production and test code, etc.), documentation & coding style and possibly performance issues; Performance and Security issues

From one side code and code changes metrics + code change patters 
would a useful information to study previous changes in the software and its documentation to learn more about upcoming (and recurrent) mistakes.
I would mine this information with some data mining techniques and machine learning to learn these patterns and/or identify some of the problems.
Ont top of this, I think auto-fixing strategies could be envisioned.

I'm a cloud developers, i.e., I dealing with cloud native (or aware) applications.
In my context, I have to dealing with several
- code and test quality checks
- performance issues; 
- security issues;
- etc.

It would be great to have tool measuring the cloud ""nativeness"" of my application, for example can we in code review  test or verify properties like ""resiliency, elasticity, low-coupling of microservices?"" This would be really useful for us and is something not available at code review and testing level.",Auto check my code for styling and for potential logical or integration issues.,"Before merge into the development/master branch, verification with a battery of tests (coverage/unit tests/integration tests/linting), and reported in a way that can be easily comprehended. ",Finding code paths that are not tested and highlighting for easy viewing. Finding places where a variable is prone to mutation where it should be copied to avoid bugs.,Security,"solutions summarizing the main problem affecting my patch, thus not a single individual feedback in one aspect, I would use some static analysis, novel metrics and summarization techniques for generating feedback related to:

interface, logic, resources, security aspect, feedback on how to improve performance of my code (if possible), quality of test and production code...

","an unified tools that provides feedback that senior developers would give me in practice, but on all issues related to doc/style/structure, interface, logic, resource, security, check large defect, configuration ASATs and CD/CI scripts","something that support me to focus on the minimal changes required for that specific review,. Each review has its own story and minimizing the feedback to the one that are relevant would be ideal to reduce the time of the review process","automation should consider more recent concept of CD, CI, and automated testing, summarization techniques, thus providing feedback on: the way a CD/CI pipeline is structured or is efficient, when the test is not of good quality suggest replacement of test suite or test methods. Summarization techniques could be useful to provide all these information in an unified manner.",I would define lightweight (not expensive metrics to compute) metrics to measure performance aspects..,"automation aimed at proposing solutions to issues like doc, style structure, resource, large defects. I would imagine an automation that provide different solutions, but developers can select the best one.","something to detect, logic imperfection compared for example the actual documentation, detection performance/resource issues, and autofixes for more common problems related to doc, style, structure","something that leverage automatic test cases generation strategies to produce better tests, or provide replacement for tests submitted for review or roviding feedback on the quality of my test code.",In line sugestions while developing.,"something that give me feedback on what improve in the artefact composing my patch, like an automated CodeReviewDoctor analyzing my patch and providing feedback on the status of the patch itself and what to change of it. This by analyzing the introduced changes, added files, etc.",for example lightweight metrics highlighting whether my code introduced performance issues.,"a comprehensive tools highlighting the changes to to perform or the defects introduced while introducing  (or evolving)  my patch, this would be really helpful.","As recommendation, I think refactorings in Code reviews should not only consider the degree of cohesion and coupling between classes only, it should also consider the degree of comprehensibility of the test and production code.

Refactoring operations should be recommended in order to simplify the way the logic of the system is implemented (removing too complex branch and conditional statements, etc.). Thus, metrics modelling, readability,  logic and comprehensibility of implemented test and production code is something desirable.

Tool recommenting the files to potentially modify maybe also specifying the specific change to perform. I think this should be possible wish some historical analysis of changes.

Recomending reviewers according to their code ownership, the fact that they introduced previous similar changes (or similar structural or semantic clones).
Having reviwers that have implemented similar stuff would be useful to detect redundant/cloned/useless code to simplify it.

Tool to directly detect redundant/cloned/useless code to simplify it.


",not sure about it.,"on the configuration level would be great to have tool suggesting
what to change over the time. For example when configuring a CD and CI pipelines, what i need to change to improve the overall developers productivity and development process. We would need metrics measuring the efficiency of a CD/CI pipeline and then understand which configuration and/or steps of the pipeline could be optimized at the configuration level. 
","as cloud developers, something to ensure the quality of my cloud applications,
in terms of performance and software quality. Thus, tools, giving me feedback on the quality of my patch, whether a new version of my patch improved in the aspects mentioned in the taxonomy. Thus, some automation based on static/dynamic analysis to provide me such information.",all elements of the taoxnomy,NA,do not know/do not want to say,not sure how to answer this
"In regards to Documentation issues, what kind of automation do you envision for the fixing and detection of these issues?","check completeness and correctness of javadoc tags with respect to rules defined by team (we try to avoid in-code documentation altogether, instead making the code easily readable to a point where javadoc is superfluous - so that's rather irrelevant for us. IDEs/compilers can already perform the tedious correctness checks if told to do so). A nice addition would be spell-checking, maybe providing suggested fixes.","I really do not understand the question; what do you mean by ""what kind of automation""? Sorry that I cannot be of any help here",Fix typos,Full,Check the use of names that are not used in the codebase,"Checking for completeness (listing of parameters, exceptions, return values for methods)",too much comments --> red flag; not sticking to documentation guidelines like Javadoc -> red flag,"- An alert --> where is a lack of documentation?
- Documentation suggestions?
- auto-generated readme file --> how to setup the application for developing",auto-doc gen which comments automatically and functionally with respect to code areas,documentation is usually not update and often incomplete. it would be great to have some automation to highlight the most relevant change that are needed to make it more complete and/or less inconsistent with the test/production code.,"Suggestions for naming fixes (cammelCase, underscore_). I often mix it up, because I happen to work with Qt that prefers cammelCase and C++ that is more fond of underscores.",A diff between the source and the documentation that listed definitions that needed to be written up in the documentation.,"As regards comments, something that is able to properly determine the goal of the entity that needs to be commented; as regard naming something that is able to suggest a proper name to assign to an entity based on the naming conventions.","in Terms of Java, I would expect that the tool could help generating the javadocs,  the license header, fix the naming conventions if possible, propose some comments (maybe templates), suggest the right modifiers. Pretty much everything.",extract real UML diagrammes from the code,"Inconsistency check (e.g., suggest documentation edit when a related code fragment changed)","fix function & class documentation, add basic documentation or make a suggestion",None. Sorry. :),Both method and variable naming according to a project convention,Detection of the right places to put comments,"detection and auto-fix would be great, as they are usually related to recurrent problem, but again in some cases the detection of the problem would be already of great help for me. I do not want waste time of other developers with always the same issue, I think such a tool would make life of developers better.","as explained before I  I would try to understand which problems are recurrent in code reviews, e.g.,  defining patterns and anti-patterns characterizing the ""software documentation"", then  defining solutions around it.",N.A,"I would expect  static tools profiling my changes in the documentation and providing me feedback encapsulating aspects related to coding or documentation styles. Clearly, even recommendations on the general required changes on a submitted patch would be really useful in my opinion.",tractability issue,"Correcting names, typos and modifiers","We require comprehensive, clear documentation and strict, simple coding style. We have our own Android code guidelines and use Android coding guidelines for contributors as a basis. “Clean Code: A Handbook of Agile Software Craftsmanship” (has recommendations on clean coding and code styling).

It would be great to have tools  able to answer the following questions automatically:

- did I have introduced imperfections at the level of documentation and coding style..?

Again, having the location (e.g., the set of files) where the problem was introduced would be relevant too..","Let me say that I would like automated feedback on production and test code for quality issues (e.g.,  structure, coverage, suggestions on how to refactoring production and test code, etc.), documentation & coding style and possibly performance issues; Performance and Security issues

From one side code and code changes metrics + code change patters 
would a useful information to study previous changes in the software and its documentation to learn more about upcoming (and recurrent) mistakes.
I would mine this information with some data mining techniques and machine learning to learn these patterns and/or identify some of the problems.
Ont top of this, I think auto-fixing strategies could be envisioned.
",Maybe auto fill ,Lint on documentation formatting to match a style.  Tools like `markdownlint` or some spell/grammar checkers that work only on docs files or on code/docs files.,Naming inconsistencies like using snake case or camel case or pascal case in some variation.,N,"i would use NLP parsing to detect recsurent issues, providing auto-fix solutions","there are many tools for detecting such issues, very few on proposing patches. Tools based on some text mining and nlp analysis to detect patterns used o correct mistakes in the documentation.","for example,  detection and auto-fix are still not available for code review, but they should be suggested only when this is relevant for the review. Metrics based on static, dynamic analysis or detection strategies based on some nlp a alysis and similar approaches would be useful here I guess.","i think tools like pmd, checkstyle alread y detect such problems, but are not always so accurate..","i think tools for this already exists, find bugs, pmd , checkstyles..","study with nlp, or other analysis recurrent patterns on how to write or not to write docs and provide potential fixes/solutions - the developers can keep the solutions they prefer", autofixes,detection of recurrent problems and auto-fixes (or recommendation of potential solutions?),Signaling when a function/class/object was incorrectly named and not found in the solution.,something that give me feedback on the quality of my documentation.,it would be fine to to have feedback on the documentation changes to perform,"a comprehensive tool highlighting the changes to to perform or the defects introduced in the documentation, while introducing (or evolving) my patch","I think documentation metrics, patterns or antipatterns in the code or in the documentation could be statically studied to determine things
-  to remove or changes (using the notion of antipatterns);
- things to add using the notion of patterns;
- detecting things that are inconsistent between documentation and the source code (this would be really useful in our continuous delivery pipeline)
",not sure about it.,not sure about this.,"automation on detecting and fixing recurrent and relevant documentation issues
for my organization",  in all elements of the taxonomy,NA,do not know/do not want to say,there are tools like check styles and pmd for java
"In regards to Style issues, what kind of automation do you envision for the fixing and detection of these issues?","auto-formatting, fixing indent and tab/spaces - but that's not the concern of a code-review tool (we have code quality tools like sonarqube for that purpose).","I really do not understand the question; what do you mean by ""what kind of automation""? Sorry that I cannot be of any help here","Formatting
Add missing annotations",Full,Most of these kind of issues should be automatically fixed by the automatic tool.,"consistend usage (eg. single line if statements) auto line break at max line length, linting for indention and white space usage, highlight TODO's","ALL OF THEM, at least recommend changes","I actually think style automation is already developed pretty good consider tools like e.g. prettier, lint  and so",auto indentation tools,"would be interesting to have a tool for evaluating my style consistency with respect to the whole project (the style applied in the organization). if checkstyle detect a style issue that is usually not remove in my organization, than, that warning is not a real issue. Style is something that is related to a specific project.",I am not so much bothered by the Style issues. Most of them are quick to fix or the IDE (Qt Creator) already takes care of it.,I feel like linters (e.g. eslint for Javascript) do a reasonable job of this. Making it easier for teams to add their own local rules would be helpful.,"Possibly, based on the output of static analysis tools try to automatically suggest a fix especially for brackets, indentation, blank lines and whitespaces",For the style? Everything should be automated. I think there are many tools already available to help on that (for example Jalopy?),I think this issue is already fixed by industrial tool such as Visual Stdio,"Fix linter style warnings (e.g., whitespace, blank lines) but don't remove TODO comments without user review !","make style suggestion if something could/can be improved, don't fix it automatically. ",None. Sorry. :),"I guess that this category is the easier one to fix, the I'll address mostly all of them",This can be done by placing a style checker in the process such that all developers obey the same style. ,I think about style issues Checkstyle and similar tools are enough... while for other problem I'm not sure there are emerging and relevant tools for automating code review.,"I think toolssuch as Checstyle already fix/handle such problems.

However, as explained before I  I would try to understand which problems are recurrent in code reviews, e.g.,  defining patterns and anti-patterns characterizing the ""code styles"", then  defining solutions around it.",N.A,"I would expect  static tools profiling my changes my code and providing me feedback encapsulating aspects related to coding styles or other aspects. Clearly, even recommendations on the general required changes on a submitted patch would be really useful in my opinion.
","probably, automatic correction can be used. but that part is a pure engineering problem.","Everything listed expect removing commented out code, since it may be important and grouping.","We require comprehensive, clear documentation and strict, simple coding style. We have our own Android code guidelines and use Android coding guidelines for contributors as a basis. “Clean Code: A Handbook of Agile Software Craftsmanship” (has recommendations on clean coding and code styling).

It would be great to have tools  able to answer the following questions automatically:

- did I have introduced imperfections at the level of documentation and coding style..?

Again, having the location (e.g., the set of files) where the problem was introduced would be relevant too..","Let me say that I would like automated feedback on production and test code for quality issues (e.g.,  structure, coverage, suggestions on how to refactoring production and test code, etc.), documentation & coding style and possibly performance issues; Performance and Security issues

From one side code and code changes metrics + code change patters 
would a useful information to study previous changes in the software and its documentation to learn more about upcoming (and recurrent) mistakes.
I would mine this information with some data mining techniques and machine learning to learn these patterns and/or identify some of the problems.
Ont top of this, I think auto-fixing strategies could be envisioned.
",Make sure the code confirms to the project style,"Tools like flake8 (python) or gometalinter (golang) and similar that detect flaws in source code.   Some of these can suggest fixes, or have companion tools (python: autopep8, golang: gofmt) that can automate these fixes.",Whitespace and indentation. These can be very easily fixed.,N,"i would use NLP analysis to study the coding style of the team/project, thus detect recurrent style issues (explaining what is wrong in my style), providing auto-fix solutions when possible..",as in the previous case:  some text mining and nlp analysis to detect patterns used o correct mistakes in the style.,similar comments as before (detection and auto-fix).,"i think tools like pmd, checkstyle alread y detect such problems, but are not always so accurate..","i think tools for this already exists, find bugs, pmd , checkstyles..",a similar automation written before but based on static analysis., autofixes ,detection of recurrent problems and auto-fixes (or recommendation of potential solutions?),Automaticly structure the code such that it confirms with the standards.,something that give me feedback on the quality of my code.,as in the previous answer,"a comprehensive tool highlighting the changes to to perform or the defects introduced in the style, while introducing (or evolving) my patch","I think style metrics, patterns or antipatterns in the code or in the documentation could be statically studied to determine things
-  to remove or changes (using the notion of antipatterns);
- things to adapt using the notion of patterns;
- detecting things that are inconsistent between documentation and the source code style (this would be really useful in our continuous delivery pipeline)",not sure about it.,not sure about this.,"automation on detecting and fixing recurrent and relevant style issues
for my organization",  in all elements of the taxonomy,NA,do not know/do not want to say,there are tools like check styles and pmd for java
"In regards to Structure issues, what kind of automation do you envision for the fixing and detection of these issues?","- medium term: provide statistics over code review changeset -> findings pairs to identify and track the main issues any given team has, finding recurring issues to improve on etc.
- in the longer term: every code review input and result should be fed into a machine learning system (neural networks, deep learning), in order to train it to detect a lot of the recurring issues within a given team.","I really do not understand the question; what do you mean by ""what kind of automation""? Sorry that I cannot be of any help here","Add missing modifiers like: static, final, public, private, etc.
Correct the case in names (camelCase, underscore_case)",Full,"In this case, the tool should assist the developers without automatically performing the changes.",hint for code duplication,"Naming, code flow, unused code detection, ...","Pattern detection with suggestion ->e.g. I see you build something which would be smart to structure in a factory pattern -> here my suggestion for it..

That would be really hard though to realise I guess, but cool",automatic re-modularization tools,"structure: it would be also interesting to get feedback 
- on the introduced  duplicated-dead code, 
- test/code smells (bad design choices) added and/or overal test/code quality and readability in general. 
etc.

Maybe this could be done by analyzing code changes?","This is an incredibly difficult task (for C++).  There have been some attempts to create tools that could help you with being coherent to the C++ Core Guidelines (as well as modernize your code base), e.g. Cevelop that has been developed at HSR Rapperswil. Unfortunately, it works with Eclipse and based on the last Twitter poll it appears that few people are using it (because of Eclipse). ","I suppose automation could, for example, warn about long methods, but I can't picture how to build a model for local convention ('Testing') or architect taste ('New Functionality').",Something aimed to propose a kind of refactoring of the actual code base,"Again I think I would expect a bit of everything. Although probably in the format of suggestions, for example, learning from past data and providing suggestions in the future? 

For example when I am about to commit class A, some features of class A (according to past data) indicates that class A should be moved to package B",code coulping,"Semantic dead code, semantic deduplication; more changes often require thorough review though","highlight dead code, unreachable code, etc. suggest refactoring options (new functions or classes), suggest code that can be removed because of duplicates...",None. Sorry. :),New functionality because is the harder thing to improve for the developers; most of the other branches of the taxonomy might be also supported by IDEs,Maybe refactoring suggestions based on coupling and cohesion metrics,"In this case, I would like to have a tool suggesting feedback on structural aspects according to any of types of artifacts I have in my patch: documentation, test and production code, etc. Possibly refactoring of tests not based only on coupling concepts but also ""incapsulating"" the need of having separated performance from functional testing and or having tests separated in  a way that they help to test different properties of microservices of cloud applications.","as explained before I  I would try to understand which problems are recurrent in code reviews, e.g.,  defining patterns and anti-patterns characterizing the ""Structure issues"", then  defining solutions around it.",N.A,"I would expect  static tools profiling my changes my code and providing me feedback encapsulating aspects related to code (and test) structure, coding styles or other aspects. Clearly, even recommendations on the general required changes on a submitted patch would be really useful in my opinion.",code smell and its score indicating whether it is worthwhile to fix the smell.,Change function,"
It would be great to have tools  able to answer the following question automatically:

- did I have introduced imperfections at the level of Architecture patterns. ?

Again, having the location (e.g., the set of files) where the problem was introduced would be relevant too..","Let me say that I would like automated feedback on production and test code for quality issues (e.g.,  structure, coverage, suggestions on how to refactoring production and test code, etc.), documentation & coding style and possibly performance issues; Performance and Security issues

From one side code and code changes metrics + code change patters 
would a useful information to study previous changes in the software and its documentation to learn more about upcoming (and recurrent) mistakes.
I would mine this information with some data mining techniques and machine learning to learn these patterns and/or identify some of the problems.
Ont top of this, I think auto-fixing strategies could be envisioned.
",Make sure there is no duplicates ,"Higher level tools like Sonarqube can detect these, but I find them to be less useful than human analysis.","Dead code, duplicate code and redundant code.",N,not sure here we need novel tool :),as in the previous case:  some text mining and nlp analysis to detect patterns used o correct mistakes in the structure.,similar comments as before (detection and auto-fix).,"i think tools like pmd, checkstyle alread y detect such problems, but are not always so accurate..","i think tools for this already exists, find bugs, pmd , checkstyles..",a similar automation written before but based on static analysis., autofixes ,detection of recurrent problems and auto-fixes (or recommendation of potential solutions?),Comment's concerning the given example in Solution Approach.,something that give me feedback on the structure of my documentation.,as in the previous answer.,"a comprehensive tool highlighting the changes to to perform or the defects introduced in the structure, while introducing (or evolving) my patch","As wrote before.

As recommendation, I think refactorings in Code reviews should not only consider the degree of cohesion and coupling between classes only, it should also consider the degree of comprehensibility of the test and production code.

Refactoring operations should be recommended in order to simplify the way the logic of the system is implemented (removing too complex branch and conditional statements, etc.). Thus, metrics modelling, readability,  logic and comprehensibility of implemented test and production code is something desirable.

Tool recommenting the files to potentially modify maybe also specifying the specific change to perform. I think this should be possible wish some historical analysis of changes.

Recomending reviewers according to their code ownership, the fact that they introduced previous similar changes (or similar structural or semantic clones).
Having reviwers that have implemented similar stuff would be useful to detect redundant/cloned/useless code to simplify it.

Tool to directly detect redundant/cloned/useless code to simplify it.",not sure about it.,not sure about this.,"automation on detecting and fixing recurrent and relevant structure issues
for my organization",  in all elements of the taxonomy,NA,do not know/do not want to say,there are tools like check styles and pmd for java
In your opinion which Topics of code changes and their Detailed Changes could be automatically detected and fixed by tools?,,,,Style and structure ,All those related to style.,"common statements like if, for, while, ...",Styling and duplicates and naming detection,Documentation suggestion I see as realiasible,I did not understand this question,"Difficult to say, ... style, documentation and structure for sure many. Corrective/Maintenance changes are the more difficult. For these cases (Corrective/Maintenance changes), even just have a predictor of required changes would be fine.","Textual Documentation, Logic(Compare), Memory Management, Data and Resource Manipulation, Variable initialization",Linters address most of the Style concerns. It seems like Structure/Organization would be the next-most low-hanging fruit. ,Style,"This question is not very clear. Is there a category called ""Code changes""? I couldn't see it.",missed property of class in processing,Style issues,"Many basic style issues which are not subject to choice or personal taste (e.g. indentation, whitespace usage, brackets, etc.). Structure: Hightlighting dead, duplicate and unreachable code... - maybe even removing it... Logic: Detecting runtime inefficiency (complexity too high maybe...)",None. Sorry. :),Documentation and style,The style section can be automated. I'm not really sure about the rest," Think the initial step is detecting the problems/issues considering the changes performed over the time, before or during the code review, then find automation for fix this problem start to be a reasonable direction for most topics :)","most of documentation/style and structure. In limited cases logic (alrogithm/perf.), resources and large defects. Maybe wrong/improper CR, CD, CI configurations? ",N.A,"I think every topics that can be quantitatively studied from the history of the project. E.g., recurrent documentation changes, or changes in the coding style would be useful to be collected and used to recommend future changes.","all the Styles, code conventions, and code duplication",Textual documentation and style,"I think it is in theory possible to  to automatically answer the questions:  - did I have introduced imperfections at the level of documentation and coding style..? - did I have introduced imperfections at the level of Architecture patterns. ? - did I have introduced imperfections at the level of Error handling and defects? - did I have introduced imperfections at the level of Test coverage and test quality? - did I have added a performance bug in my change? - did I have added a security bug in my change?  I also believe that it would be possible to find out the location (e.g., the set of files) where the problems were introduced.","feedback on production and test code for quality issues (e.g.,  structure, coverage, suggestions on how to refactoring production and test code, etc.), documentation & coding style . Performance and Security issues are the more difficult to automate I guess, but can we monitor the with performance or security metrics?","Styling, integration problems.   ",most style and static structure analysis could be,Finding redundant and duplicate code,N,"any of: interface, logic, resources, security aspect, feedback on how to improve performance of my code (if possible), quality of test and production code. Important to mention that all of these require new metrics and concepts. I t would be cool to have a tool that detect introduce performance (or test quality) issues during code review and before put the changes in the CD/CI pipeline.","logic, tests quality, ASAT configuration, doc, style, structure, performance more difficult is security..",I would say most of them.,"automation should consider more recent concept of CD, CI, and automated testing, summarization techniques, thus providing feedback on: the way a CD/CI pipeline is structured or is efficient, when the test is not of good quality suggest replacement of test suite or test methods. Summarization techniques could be useful to provide all these information in an unified manner.","feedback on performance, security, style, documentation. Logic is difficult, but could be detected by analyzing both documentationa and code and detecting inconsistencies.","I think also on ""resource, and simple defects"" many problems are very recurrent in code review and I think this make it possible to predict or suggest recommendations for them.","doc, styl, structure, interface,  resources","most of doc/style/structure/check, etc. detection of recurrent problems and auto-fixes. For testing, as explained before.",Nameing in documentary,it depends on the automation we want to implement. Having an automated initial feedback on the quality of the patch would be great. Then semi-automated solutions could be integrated ...,"performance, gui,  and configuration need still some automated support in code reviews","most of them, the defects are usually less easy to detect (humans are more efficient on this), but tools can at least help on locating it.","for sure on style, documentation, structure, logic, other changes, resources, .. ",most of them I think,I think in theory all of changes of the taxonomy that are not strictly related to detection of defects,"most of them but in different ways: (i) some of the could be just recommended to change, while other could be also autofixed, or solutions could be proposed by analysing historical changes and data from repositories (e.g., versioning systems and issue tracking system).",  in all elements of the taxonomy,NA,do not know/do not want to say,not sure how to answer this
Briefly describe how you would approach the detection and fixing of the issues described in your last answer.,,,,Automatic correction and notification ,Automatically fixing the issues before committing.,"detection: regex parsing, fixing: applying correct code structure","IntelliJ includes recommendation while programming, something in that style.","Try to find characteristics e.g. for a method description based on the code itself 
--> can I use method name + parameters + other method and classes called within the method + instantiation + .... to predict what that method actually does --> can I generate documentation out of it?",I did not understand the previous question,I basically explained it in the survey :),"These kind of tools already exist, but are not necessarily integrated with the commonly used IDEs (e.g. valgrind for memory checks). For other things (initialization, undefined behavior, logic compare) I would prefer to rely on the compiler. For textual documentation, I would like the IDE to handle the naming.","As alluded to above, existing variables, statements, and functions could be used as models when reviewing new code.",Look at the answer given to the Style issues comment. try to automatically apply basic fix aimed to change the style like add whitespace or remove blank lines,"Considering the topics ""Solution Approach"" and ""Organization"", I would first check the literature for each Detailed Change to understand the ""State of the Art"" of automatic detection for that specific Detailed Change. In this way I would work on automatically detecting each part first and in the end I would have an entire framework (much a like a divide to conquer strategy).",for example missing an data filed in new and edit forms,Enforce linter rules and propose a pull request with the changes,see as quickly describe after each statement/topic above.,Not applicable.,"For documentation and style issue I guess that's a easier to develop an approach. Actually, some of them already implement things like renaming of variables, generation of comments and so on. Regarding the style, somethings very simple like regex might be sufficient","There are many code checkers out there (FindBugs, ScalaStyle, PMD, ...). Maybe implement an integration with one of these tools during the reviewing process."," As discussed before,  the initial step is detecting the problems/issues considering the changes performed over the time, before or during the code review, then find automation for fix the problems start to be a reasonable/easier thing to do in most topics :)"," I would try to understand which problems are recurrent in code reviews, e.g.,  defining patterns and anti-patterns characterizing the ""code review process and collaborations"".  The I would automatically leverage tools for detecting such anti-patterns to highlight potential problems. Many of problems we face during code review are related to the miss match between expectations and outcomes of a code review. Reviewer provide feedback that are not exhaustive or timely reported. This makes often code reviews unproductive. A simple automation toward this direction could be predicting the required code review changes.",N.A,I think I answered this in the previous message (just apply that methodology to other topics in your taxonomy),"use template or patterns to conduct the auto-correctness. moreover, there are existing code clone detection to this end. however, not all the duplication should be refactored or merged, which brings the challenge for research to locate the merge/refactor-oriented code duplication.",Naming: find the convention used mostly throughout the project and conform the remaining of names with it. Similarly for the rest. Whitespace usage: remove all the unnecessary white space (if there are two spaces between tokens etc).,"Already described, but i think the best idea is to have a look at changes to heterogeneous types of data and recurrent change patterns to provide the automation i have envisioned/mentioned before.","From one side code and code changes metrics + code change patters 
would a useful information to study previous changes in the software and its documentation to learn more about upcoming (and recurrent) mistakes.
I would mine this information with some data mining techniques and machine learning to learn these patterns and/or identify some of the problems.
Ont top of this, I think auto-fixing strategies could be envisioned.",Manually ,"Running tools that perform this analysis, and present findings in the code review system.","Static analysis of the code and having a couple of possible solutions to the problem. If a function is duplicated between two classes, that may be intentional to avoid coupling those classes, so we might want to ignore it. But if a function is duplicated within two classes that both inherit from the same parent class than the solution would be to put that function in the parent class.",N,"For each problem/issues, I would focus on recurrent and relevant metrics, patterns and anti-patters (in some case NLP patterns, in other based on dynamic and static information) then on solutions  to detect, recommend or auto-fix them. ","as  previously mentioned:  some text mining and nlp analysis to detect patterns used o correct mistakes in the structure. In other case nlp or test mining would be not enough and some static, dynamic analysis of code under review would be  required (for example for logic and other issues).","similar comments as before (detection and auto-fix) with Metrics based on static, dynamic analysis or detection strategies based on some nlp a alysis and similar approaches.","I would for sure try to learn more about the way people configure CD/CI pipelines, ASATs tools. Automation should consider more recent concept of CD, CI, and automated testing, summarization techniques, thus providing feedback on: the way a CD/CI pipeline is structured or is efficient, when the test is not of good quality suggest replacement of test suite or test methods. Metrics, dynamic/performance/static analysis, summarization techniques could be useful to provide all these information in an unified manner.",I would define lightweight (not expensive metrics to compute) metrics to measure of detect  the issues.,"empirical analysis, usage of nlp, static analysis, dynamic analysis,  definition of new metrics, studying recurrent patterns on how to model, detect and propose fixes for doc, style structure, resource, large defects.  - Then the developers can keep the solutions they prefer.","I would try to analyze code and other changes from the history of the project, detecting, metrics patterns, anti-patterns, thus predicting required changes, or recommending solution when possible.","Recommendation of potential solutions: something that leverage automatic test cases generation strategies to produce better tests, or provide replacement for tests submitted for review or providing feedback on the quality of my test code. For other problems: detection of recurrent problems and auto-fixes (or recommendation of potential solutions?).",Regex through code.,"As mentioned before, something that give me feedback on what improve in the artefact composing my patch, like an automated CodeReviewDoctor analyzing my patch and providing feedback on the status of the patch itself and what to change of it. This by analyzing the introduced changes, added files, etc.
- A fully automated solution should provide feedback on the change to perform,
- then a semi-automated approach should be enacted on top of the CodeReviewDoctor or CodeReviewChangeDetector,  something like a CodeReviewChangeGenerator that provide potential solution to integrate in the current patch.","for example lightweight metrics highlighting whether my code introduced performance issues., or recurrent issues in configuration files.","build a comprehensive tool highlighting the changes to perform or the defects introduced in the documentation, while introducing (or evolving) my patch. This would require a tool analysing the code and other software artifacts changes from the first version of the patch and over the time, until the patch is ready to be submitted to the master repository. The tools should monitor  specific and evolving characteristics of the patch providing feedback on what improved over the time and what do not. Metrics based on code change analysis would be one solutions, but they should be provided in an unified manner.","I think I have explained a bit how I would approach this. I would use the notion of patterns, antipatterns to also fix/handle problems on resource consumption of my code, something not available in code review practices.",not sure about it.,"on the configuration level would be great to have tool suggesting
what to change over the time. For example when configuring a CD and CI pipelines, what i need to change to improve the overall developers productivity and development process. We would need metrics measuring the efficiency of a CD/CI pipeline and then understand which configuration and/or steps of the pipeline could be optimized at the configuration level. ",I think i have discussed it already in previous questions.,  in all elements of the taxonomy,NA,do not know/do not want to say,not sure how to answer this
"If you have any additional comments or questions, please feel free to write them here or send us your feedback per e-mail.",,,,,,,,"It sounds like a really interesting project. I think what is really important at developing a code for automated code review is that it is really reliable. As if you have to review the auto-generated reviews manually, you have again more workload and it does not help at all",,"It is a research project in the right direction, automating Code review practices is still something should be achieved by industrial and research organizations.",It was a bit tricky to navigate in the table. Wishing you all the best!,,,"I think your taxonomy can still be improved in terms of descriptions. The green part is very well documented, but the other parts are more difficult to understand, since less material is provided.",,the survey feels quite long to complete,thanks!,"You seem to assume that the CR process can be automated, at least to some extent. I think this is a very strong assumption and I would strongly recommend you to validate this assumption, first!","I'd elaborate a bit more the ""Other Changes"" part of the taxonomy. You worked a log on the upper part, while the that one seems to be there just because. It was a bit ambiguous to me the ""after delivery"" you use in both Production & Test Code sub-categories. Isn't code review a prerequisite for the software delivery. Just as a minor thing, some practical example (I mean actual code) might help to figuring out the categories",I truly believe that the code reviewing process is about human interaction. It serves as a communication platform where the developers ask questions and learn from each other. So maybe the direction to automate this process is not the best one.,,,,"I'm glad research focus on our expectation from future tools for code review, I would be really interested to know about the outcome of this research.",llmhyy@gmail.com (Yun Lin),/,"Thanks for inviting me to this interesting survey, I hope  that i have helped you with ideas to shape future research on code review practices.",,,zdw@opennetworking.org,,,this is a relevant research and as developer I support it :),,,,,,,,,,,,,,,,,,,
